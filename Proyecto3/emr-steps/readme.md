Este documento describe en detalle los **Steps ejecutados en Amazon EMR** para el procesamiento ETL y anal√≠tico del Proyecto 3. Incluye:

- Scripts usados en cada Step
- Comandos ejecutados
- Lugar donde se usan
- Requisitos previos
- C√≥mo reproducir los Steps
- Resultados esperados

---

## 1. Introducci√≥n

En este proyecto, Amazon EMR se utiliz√≥ como motor de procesamiento distribuido con **Apache Spark**.  
El cl√∫ster ejecuta dos Steps principales:

1. **ETL (Transformaci√≥n de datos)**  
   Script: `etl_covid.py`

2. **Analytics (C√°lculo de m√©tricas)**  
   Script: `analytics_covid.py`

Ambos scripts se almacenan en:

```
s3://vladdatalake/scripts/emr/
```

---

## 2. Scripts utilizados en EMR

### 2.1 Script ETL ‚Äì `etl_covid.py`

Ruta en S3:

```
s3://vladdatalake/scripts/emr/etl_covid.py
```

Funci√≥n:

- Leer archivos Parquet desde la zona **RAW** en S3.
- Limpiar / transformar datos.
- Escribir el resultado en la zona **PROCESSED**:

```
s3://vladdatalake/processed/covid/
```

---

### 2.2 Script Analytics ‚Äì `analytics_covid.py`

Ruta en S3:

```
s3://vladdatalake/scripts/emr/analytics_covid.py
```

Funci√≥n:

- Leer datos desde la zona **PROCESSED**.
- Generar m√©tricas o agregaciones.
- Guardar resultados en **ANALYTICS**:

```
s3://vladdatalake/analytics/covid/
```

---

## 3. Creaci√≥n del cl√∫ster EMR

Antes de agregar los Steps, se cre√≥ un cl√∫ster EMR con la siguiente configuraci√≥n:

- **Aplicaciones**: Spark, Hadoop  
- **Versi√≥n de EMR**: 6.x  
- **Flota**: 1 Master + 1 Core  
- **Tipo de instancias**: m5.xlarge
- **VPC**: misma VPC de RDS y Glue  
- **Logging habilitado**:  
  ```
  s3://vladdatalake/emr-logs/
  ```

---

## 4. Steps ejecutados

---

### üü© STEP 1: ETL ‚Äì RAW ‚Üí PROCESSED

**Nombre del Step:** `etl_covid`  
**Tipo:** Spark application  
**Comando (`Arguments`):**

```
spark-submit --deploy-mode cluster --master yarn s3://vladdatalake/scripts/emr/etl_covid.py
```

**Resultado esperado:**  
En caso de √©xito aparece:

```
processed/covid/
    part-0000*.parquet
    _SUCCESS
```

---

### üü¶ STEP 2: Analytics ‚Äì PROCESSED ‚Üí ANALYTICS

**Nombre del Step:** `analytics_covid`  
**Tipo:** Spark application  
**Comando (`Arguments`):**

```
spark-submit --deploy-mode cluster --master yarn s3://vladdatalake/scripts/emr/analytics_covid.py
```

**Resultado esperado:**

```
analytics/covid/
    part-0000*.parquet
    _SUCCESS
```

---

## 5. C√≥mo reproducir los Steps si el EMR es eliminado

1. Crear un nuevo cl√∫ster EMR con Spark.  
2. Agregar Step 1 (ETL):

```
spark-submit --deploy-mode cluster --master yarn s3://vladdatalake/scripts/emr/etl_covid.py
```

3. Agregar Step 2 (Analytics):

```
spark-submit --deploy-mode cluster --master yarn s3://vladdatalake/scripts/emr/analytics_covid.py
```

---

## 6. Estructura esperada del S3

```
vladdatalake/
  raw/
    rds/covid_complement/
  processed/
    covid/
  analytics/
    covid/
  scripts/
    emr/
      etl_covid.py
      analytics_covid.py
```

---

## 7. Logs del EMR

Todos los logs se guardan autom√°ticamente en:

```
s3://vladdatalake/emr-logs/<cluster-id>/steps/<step-id>/
```

Incluyendo:
- stdout.gz  
- stderr.gz  
- controller.gz  

---
